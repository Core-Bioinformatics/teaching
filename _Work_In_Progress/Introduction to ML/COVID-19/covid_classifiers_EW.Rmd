---
title: "COVID-19 dataset classifiers"
output: html_document
---

# Testing k-NN, Decision Tree, Random Forest and SVMs on COVID-19 dataset

### Loading libraries

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r loading libraries,echo=FALSE,warning=FALSE}
library(ggplot2)
library(GGally)
if(!require(plyr)){install.packages("plyr")}
library(plyr)
if(!require(dplyr)){install.packages("dplyr")}
library(dplyr)
if(!require(reshape2)){install.packages("reshape2")}
library(reshape2)
if(!require(caret)){install.packages("caret")}
library(caret)
if(!require(corrplot)){install.packages("corrplot")}
library(corrplot)
if(!require(rpart.plot)){install.packages("rpart.plot")}
library(rpart.plot)

```

## Loading and summarising dataset

```{r loading data}
covid.data <- read.csv("covid_final.csv",header=T)
covid.data = covid.data[,2:ncol(covid.data)]
covid.data$result = as.factor(covid.data$result)
head(covid.data)
summary(covid.data)
str(covid.data)
```


```{r violin}
ggplot(covid.data, aes(result, location, fill=result)) +
  geom_violin(aes(color = result), trim = T)+
  scale_y_continuous("Location", breaks= seq(0,150, by=10))+
  geom_boxplot(width=0.1)+
  theme(legend.position="none")

ggplot(covid.data, aes(result, country, fill=result)) +
  geom_violin(aes(color = result), trim = T)+
  scale_y_continuous("Country", breaks= seq(0,50, by=5))+
  geom_boxplot(width=0.1)+
  theme(legend.position="none")

ggplot(covid.data, aes(result, symptom1, fill=result)) +
  geom_violin(aes(color = result), trim = T)+
  scale_y_continuous("Symp1", breaks= seq(0,25, by=2))+
  geom_boxplot(width=0.1)+
  theme(legend.position="none")

ggplot(covid.data, aes(result, age, fill=result)) +
  geom_violin(aes(color = result), trim = T)+
  geom_boxplot(width=0.1)+
  theme(legend.position="none")

```

```{r jitter}
pdf("vio_jitter_covid.pdf", width = 10, height = 5)
exploratory.covid <- melt(covid.data)
exploratory.covid %>%
  ggplot(aes(x = factor(variable), y = value)) +
  geom_violin() +
  geom_jitter(height = 0, width = 0.1, aes(colour = result), alpha = 0.7) +
  theme_minimal()
dev.off()
```

```{r ggpairs}
pdf("all_info_covid.pdf", width=20, height=20)
ggpairs(covid.data, ggplot2::aes(colour = result, alpha = 0.4))
dev.off()

```
## Splitting into training and test data

```{r splitting into training and test}
covidClass <- covid.data$result
covidData <- covid.data[,1:13]

set.seed(42)
trainIndex <- createDataPartition(y=covidClass, times=1, p=0.7, list=F)
classTrain <- covidClass[trainIndex]
dataTrain <- covidData[trainIndex,]
classTest <- covidClass[-trainIndex]
dataTest <- covidData[-trainIndex,]
summary(dataTrain)
summary(dataTest)
```
## Identifying zero or near zero variance features

```{r near zero var}
nzv <- nearZeroVar(dataTrain, saveMetrics=T)
print(nzv)
print(rownames(nzv[nzv$nzv==TRUE,]))
listtoexclude = c(rownames(nzv[nzv$nzv==TRUE ,]))
listtoexclude = c(listtoexclude,rownames(nzv[nzv$zeroVar==TRUE ,]))
```

```{r feature plot}
featurePlot(x = dataTrain,
            y = classTrain,
            plot = "box",
            ## Pass in options to bwplot()
            scales = list(y = list(relation="free"),
                          x = list(rot = 90)),
            layout = c(3,3))

#density plot for each variable in training set
featurePlot(x = dataTrain,
            y = classTrain,
            plot = "density",
            ## Pass in options to xyplot() to
            ## make it prettier
            scales = list(x = list(relation="free"),
                          y = list(relation="free")),
            adjust = 1.5,
            pch = "|",
            layout = c(3, 3),
            auto.key = list(columns = 3))

```
## Identifying highly correlated features

```{r correlation plot}
corMat <- cor(dataTrain)
corrplot(corMat, order="hclust", tl.cex=1)
highCorr <- findCorrelation(corMat, cutoff=0.5)
length(highCorr)
names(dataTrain)[highCorr]
listtoexclude = c(listtoexclude,names(dataTrain)[highCorr])
```
## k-NN

```{r train control}
tuneParam <- data.frame(k=seq(1,50,2))
set.seed(42)
seeds <- vector(mode = "list", length = 101)
for(i in 1:100) seeds[[i]] <- sample.int(1000, length(tuneParam$k))
seeds[[101]] <- sample.int(1000,1)

train_ctrl <- trainControl(method="repeatedcv",
                           number = 10,
                           repeats = 10,
                           preProcOptions=list(cutoff=0.75),
                           seeds = seeds)

```

We can try first using all the features but then we will exclude the near zero-variance and highly correlated features.

```{r kNN full feature set}
knnFit <- train(dataTrain, classTrain,
                method="knn",
                preProcess = c("center", "scale", "corr"),
                tuneGrid=tuneParam,
                trControl=train_ctrl)
knnFit
#plotting accuracy against k
plot(knnFit)
plot(knnFit,metric="Kappa")

```


```{r test performance}
test_pred <- predict(knnFit, dataTest)
confusionMatrix(test_pred, classTest)
```

```{r remove bad features kNN}
dataTrain_restricted = dataTrain[, -which(names(dataTrain) %in% listtoexclude)]

dataTest_restricted = dataTest[, -which(names(dataTest) %in% listtoexclude)]

train_ctrl_restricted <- trainControl(method="repeatedcv",
                           number = 10,
                           repeats = 10,
                           preProcOptions=list(cutoff=0.75),
                           seeds = seeds)

knnFit_restricted <- train(dataTrain_restricted, classTrain,
                method="knn",
                preProcess = c("center", "scale", "corr"),
                tuneGrid=tuneParam,
                trControl=train_ctrl_restricted)
knnFit_restricted
plot(knnFit_restricted)
plot(knnFit_restricted,metric="Kappa")

test_pred <- predict(knnFit_restricted, dataTest_restricted)
confusionMatrix(test_pred, classTest)
```

## Decision Trees

```{r decision tree}
dtFit <- train(dataTrain_restricted, classTrain,
                method="rpart",
                preProcess = c("center", "scale"),
                tuneLength=10,
                trControl=train_ctrl_restricted)
dtFit
plot(dtFit)
plot(dtFit,metric="Kappa")

test_pred <- predict(dtFit, dataTest_restricted)
confusionMatrix(test_pred, classTest)
```
We can see the resulting Decision Tree to understand the features which contributed most strongly to classification. We can also see the variable importance.

```{r plot decision tree}
prp(dtFit$finalModel)
plot(varImp(dtFit))
```
```{r}
dataTrain_factor = subset(dataTrain_restricted,select=-c(location))
dataTrain_factor$gender = as.factor(dataTrain_restricted$gender)
dataTrain_factor$country = head(as.factor(c(dataTrain$country,dataTest$country)),length(dataTrain$country))
dataTrain_factor$vis_wuhan = as.factor(dataTrain_restricted$vis_wuhan)
dataTrain_factor$from_wuhan = as.factor(dataTrain_restricted$from_wuhan)
dataTrain_factor$symptom1 = head(as.factor(c(dataTrain$symptom1,dataTest$symptom1)),length(dataTrain$symptom1))

dataTest_factor = subset(dataTest_restricted,select=-c(location))
dataTest_factor$gender = as.factor(dataTest_restricted$gender)
dataTest_factor$country = tail(as.factor(c(dataTrain$country,dataTest_restricted$country)),length(dataTest$country))
dataTest_factor$vis_wuhan = as.factor(dataTest_restricted$vis_wuhan)
dataTest_factor$from_wuhan = as.factor(dataTest_restricted$from_wuhan)
dataTest_factor$symptom1 = tail(as.factor(c(dataTrain$symptom1,dataTest$symptom1)),length(dataTest$symptom1))

dtFit <- train(dataTrain_factor, classTrain,
                method="rpart",
                preProcess = c("center", "scale"),
                tuneLength=10,
                trControl=train_ctrl_restricted)
plot(dtFit)
plot(dtFit,metric="Kappa")

test_pred <- predict(dtFit, dataTest_factor)
confusionMatrix(test_pred, classTest)
prp(dtFit$finalModel)
plot(varImp(dtFit))
```

## Random Forest

```{r random forest}

rfFit <- train(dataTrain_factor, classTrain,
                method="rf",
                preProcess = c("center", "scale"),
                tuneLength=10,
                trControl=train_ctrl_restricted)
plot(rfFit)
plot(rfFit,metric="Kappa")

test_pred <- predict(rfFit, dataTest_factor)
confusionMatrix(test_pred, classTest)
```

Here we can use the in-built variable importance to understand the features which contribute most strongly.

```{r varImp random forest}
plot(varImp(rfFit))
```
```{r comparing dt rf}
resamps <- resamples(list(Dtree = dtFit, RF = rfFit))
summary(resamps)
bwplot(resamps, metric = "Accuracy")
densityplot(resamps, metric = "Accuracy",auto.key=TRUE)
```


## SVM

For SVM, we need to decide which kernel performs best. We will train 3 different types of kernel through cross-validation then compare the results. We use linear, polynomial and radial kernels.

```{r SVM linear}
tuneParam <- data.frame(k=seq(1,50,2))
set.seed(42)
seeds <- vector(mode = "list", length = 101)
for(i in 1:100) seeds[[i]] <- sample.int(1000, 300)
seeds[[101]] <- sample.int(1000,1)

train_ctrl <- trainControl(method="repeatedcv",
                           number = 10,
                           repeats = 10,
                           preProcOptions=list(cutoff=0.75),
                           seeds = seeds)

L_models <- train(dataTrain_restricted, classTrain,
                method="svmLinear",
                preProcess = c("center", "scale"),
                tuneLength=4,
                trControl=train_ctrl)

```
```{r SVM poly}
P_models <- train(dataTrain_restricted, classTrain,
                method="svmPoly",
                preProcess = c("center", "scale"),
                tuneLength=4,
                trControl=train_ctrl)
```
```{r SVM radial}
R_models <- train(dataTrain_restricted, classTrain,
                method="svmRadial",
                preProcess = c("center", "scale"),
                tuneLength=4,
                trControl=train_ctrl)

resamps <- resamples(list(Linear = L_models, Poly = P_models, Radial = R_models))
summary(resamps)
bwplot(resamps, metric = "Accuracy")
densityplot(resamps, metric = "Accuracy",auto.key=TRUE)
```

Here, the polynomial kernel performs consistently well so we can look at the variable importance and confusion matrix for this model. We get a breakdown here comparing different degree options for the polynomial SVM (here 3 was selected).

```{r radial SVM}

plot(P_models)
plot(P_models,metric="Kappa")
plot(R_models)
plot(R_models,metric="Kappa")

test_pred <- predict(R_models, dataTest_restricted)
confusionMatrix(test_pred, classTest)
plot(varImp(R_models))
```
## Comparing the models

```{r comparing models}
resamps <- resamples(list(kNN = knnFit_restricted, Dtree = dtFit, RF = rfFit, SVM = R_models))
summary(resamps)
bwplot(resamps, metric = "Accuracy")
densityplot(resamps, metric = "Accuracy",auto.key=TRUE)
```
Both SVMs and Random Forest perform well with Random Forest coming out slightly better (which is what the authors of the paper also concluded).
